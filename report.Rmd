---
title: "Final Project"
author: "London Wagner, Erik Lovece, Carmen Canedo"
date: "`r Sys.Date()`" # 4/24/21
output:
  pdf_document:
    number_sections: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(leaps)
library(glmnet)
library(pls)
library(car)
library(tidyverse)
```

# Introduction

Our final project analyzes the student performance dataset from the UCI Machine Learning Repository, originally gathered by Paulo Cortez from the University of Minho. This dataset measures the final student grade in a Portuguese class based on a variety of predictors. These predictors cover numerous aspects of not only students' academic lives, but also family life predictors such as parental employment, and personal predictors like whether or not they have home internet access and whether or not they are in a romantic relationship.

We seek to answer the question of what predictors have the greatest influence in how a student does in class. Conventional wisdom seems to dictate that high-achieving students have come from particularly favorable academic, filial, and personal environments, and previous studies have confirmed this. Our model, if properly constructed along the best machine learning practices, should corroborate this, although unexpected conclusions may also lie in store.

Our workflow for finding a sufficient model from which we will draw our conclusions is as follows:

1) Run a linear regression model with final grade as the response and all other variables as predictors 
2) Use best subset, forward step, and backwards step to select variables for a reduced model
3) Use ridge, lasso, principal component regression, and partial least squares regression to conduct further dimension reduction
4) Use cross validation methods to determine which model predicts the final grade with the greatest accuracy
5) Make more definitive determinations based on the chosen model.

# Loading Data

```{r message=FALSE}
student_por <- read_csv2("data/student-por.csv")

student_por
```

The student attributes and grades forming the predictors and response, quoted verbatim from a text file provided with the dataset, are as follows:

1 school - student's school (binary: "GP" - Gabriel Pereira or "MS" - Mousinho da Silveira)

2 sex - student's sex (binary: "F" - female or "M" - male)

3 age - student's age (numeric: from 15 to 22)

4 address - student's home address type (binary: "U" - urban or "R" - rural)

5 famsize - family size (binary: "LE3" - less or equal to 3 or "GT3" - greater than 3)

6 Pstatus - parent's cohabitation status (binary: "T" - living together or "A" - apart)

7 Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)

8 Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)

9 Mjob - mother's job (nominal: "teacher", "health" care related, civil "services" (e.g. administrative or police), "at_home" or "other")

10 Fjob - father's job (nominal: "teacher", "health" care related, civil "services" (e.g. administrative or police), "at_home" or "other")

11 reason - reason to choose this school (nominal: close to "home", school "reputation", "course" preference or "other")

12 guardian - student's guardian (nominal: "mother", "father" or "other")

13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)

14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)

15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)

16 schoolsup - extra educational support (binary: yes or no)

17 famsup - family educational support (binary: yes or no)

18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)

19 activities - extra-curricular activities (binary: yes or no)

20 nursery - attended nursery school (binary: yes or no)

21 higher - wants to take higher education (binary: yes or no)

22 internet - Internet access at home (binary: yes or no)

23 romantic - with a romantic relationship (binary: yes or no)

24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)

25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)

26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)

27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)

28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)

29 health - current health status (numeric: from 1 - very bad to 5 - very good)

30 absences - number of school absences (numeric: from 0 to 93)

31 G1 - first period grade (numeric: from 0 to 20)

31 G2 - second period grade (numeric: from 0 to 20)

32 G3 - final grade (numeric: from 0 to 20, output target)

For all of our models, `G3` is our response and every other variable serves as a predictor (pending elimination).

# Data Cleaning

When creating our models, some variables need be converting to factors in order to be properly interpreted by the `lm` function. We have converted the necessary variables, so now many of them (with special emphasis on binary variables) are now of type factor.

```{r, include=FALSE}
student_por <-
  student_por %>%
  mutate(school = factor(school),
         sex = factor(sex),
         address = factor(address),
         famsize = factor(famsize),
         Pstatus = factor(Pstatus),
         schoolsup = factor(schoolsup),
         famsup = factor(famsup),
         paid = factor(paid),
         activities = factor(activities),
         nursery = factor(nursery),
         higher = factor(higher),
         internet = factor(internet),
         romantic = factor(romantic),
         reason = factor(reason))
```

```{r}
student_por
```

# Exploratory Data Analysis & Checking Assumptions

Before we begin our analysis, we wish to explore the distribution of the data and confirm it follows the typical assumptions of linear regression. Although we recognize that these assumptions are not as necessary in machine learning, they can be helpful when determining what kind of model we should use to predict our response variable, G3.

```{r}
summary(student_por)
```

Most noteworthy is how G1, G2, and G3's $1^{st}$ quartile of 10 is quite close to the median and mean on the 0-20 scale, yet the minimum in all three is zero. There is a significant gap between the lower and minimum behavior, and these lowest-end students may influence our subsequent analyses in some way.

```{r}
student_por %>% 
  ggplot(aes(x = G3)) +
  geom_histogram()
```

```{r}
lowest <- filter(student_por, G3 == 0)
num_lowest <- nrow(lowest)
num_lowest / nrow(student_por)

lowest
```

As expected, the lowest-performing students left-skew the distribution of the final scores. However, it is not a couple isolated cases, but 2.3% of the student population in this class. Although there are some commonalities among these students (most of them attended nursery school but did not pay for extra educational support in this subject field, and they all had zero absences), we will later find that most of these factors in common are unimportant in our final models. For now, we run the model taking every student into account.

## Running `lm`

```{r}
por_reg <- lm(G3 ~ ., data = student_por)
summary(por_reg)
```

Most variables in our many-variable linear model do not seem useful to us, prompting the use of best subset and dimension-reducing methods. To showcase other model deficiencies, we produce several plots of the residual distribution:

```{r}
par(mfrow = c(2, 3))
plot(por_reg)

hist(por_reg$residuals)

shapiro.test(por_reg$residuals)
```

We see that the residuals are not randomly distributed per the residual plot and the QQ-plot yields residuals clearly left-skewed from normality. Shapiro-Wilk test run on the residuals gives us the utmost confidence that they do not have normal distribution. Future analysis may seek to analyze the possible high-leverage points and potential outliers as shown in the residuals vs. leverage plot, but this is outside the scope of this project and there are better-fitting methods to consider.

## Finding Linear Regression MSE

Even though our initial model does not suit our needs, we can still calculate the prediction MSE as a baseline to compare future models to, anticipating that subsequent models will be more accurate.

```{r}
set.seed(1)
n <- nrow(student_por)
Z <- sample(n, .7*n)

reg.fit <- lm(G3 ~ ., data = student_por, subset = Z)
```

```{r}
g3_predicted <- predict(reg.fit, student_por)
```

```{r}
plot(student_por$G3[-Z], g3_predicted[-Z], xlab = "Actual Grades", ylab = "Predicted Grades", main = "Prediction Accuracy of Full Linear Model")
abline(0,1)
```

We can see on the left side of the graph, when the actual G3 (final grade) is 0, the model tends to overestimate.

```{r}
mse_lm <- mean((student_por$G3 - g3_predicted)[-Z]^2)
mse_lm
```

Despite its flaws, the linear model has a rather low MSE (1.550) for scores strictly on a 0-20 scale. When looking for a better model, we will use methods in an attempt to reduce the number of variables or the number of dimensions in the dataset. Therefore we will be using best subset, forward and backwards step, LASSO, Ridge, PCR, and PLS. First, we will start with Best Subset.

## Best Subset

When initially running our best subset, we decided to cap the number of variables at 15. This was done in order to ensure the model has enough variables to predict G3 accurately without including unnecessary ones that would complicate the model. 

```{r}
# Takes a while to run

subsets <- regsubsets(G3 ~ ., data = student_por, nvmax = 15)
```

```{r, include = FALSE}
summary(subsets)
```

```{r}
summary(subsets)$adjr2
summary(subsets)$cp
summary(subsets)$bic
```

## Set validation for Best Subset
## Best Subset

```{r}
which.max(summary(subsets)$adjr2)
which.min(abs(summary(subsets)$cp - 1:15))
which.min(summary(subsets)$bic)
```

When looking at the adjr2 value, we can tell that they are all relatively the same, ranging from 0.843 to 0.854. Because adding in more variables did not make a significant difference on this value, we are not going to propose a candidate model based on the highest adjr2. Instead, we will move forward with two candidate models, one with five variables as suggested by the Mallow's Cp and one with three variables as suggested by the BIC.

## Model Based on Mallow's Cp

Based on the output from Best Subset, we are going to run a model that includes the variables:
- sex
- reason
- failures
- G1
- G2

```{r}
reg.bestsubCP <- lm(G3 ~ sex + reason + failures + G1 + G2, data = student_por, subset = Z)

g3_pred_bestsubCP <- predict(reg.bestsubCP, student_por)
```

```{r}
plot(student_por$G3[-Z], g3_pred_bestsubCP[-Z], xlab = "Actual Grades", ylab = "Predicted Grades", main = "Predicted vs. Actual Grades of Reduced Model Based on Cp")
abline(0,1)
```

Similar to the Predicted vs. Actual Grade plot for the initial linear regression, the Mallow's Cp model (with five variables) overestimates the final grade (G3) when the actual grade is 0. These data points are potential outliers, but removing them is outside of the scope of this project. Otherwise, the model fits the rest of the data well.

```{r}
mse_cp <- mean((student_por$G3 - g3_pred_bestsubCP)[-Z] ^ 2)
mse_cp
```

The MSE for the Best Subset Model based on Mallow's C is 1.474.

## Model Based on BIC

Based on the output from Best Subset, we are going to run a model that includes the variables:
- reason
- G1
- G2

```{r}
reg.bestsubBIC <- lm(G3 ~ reason + G1 + G2, data = student_por, subset = Z)

g3_pred_bestsubBIC <- predict(reg.bestsubBIC, student_por)
```

```{r}
plot(student_por$G3[-Z], g3_pred_bestsubBIC[-Z], xlab = "Actual Grades", ylab = "Predicted Grades", main = "Predicted vs. Actual Grades of Reduced Model Based on BIC")
abline(0,1)
```

Again, this plot is very similar to those for the previous models. 

```{r}
mse_bic <- mean((student_por$G3 - g3_pred_bestsubBIC)[-Z] ^ 2)
mse_bic
```

The MSE for the Best Subset Model based on BIC is 1.427.

## Step Functions

Now we are going to be looking at forward and backward step functions.

```{r include=FALSE}
null <- lm(G3 ~ 1, data = student_por)
full <- lm(G3 ~ ., data = student_por)

forward <- step(null, scope = list(lower=null, upper = full), direction = "forward")
backward <- step(full, scope = list(lower=null, upper = full), direction = "backward")
```

```{r}
summary(forward)
summary(backward)
```

Forward and backward step functions yield the exact same model; proceeding with forward step-generated model.

## Set validation

Based on the output from Forward Step, we are going to run a model that includes the variables:
- failures
- reason
- absences
- sex
- school
- traveltime
- health
- G1
- G2

```{r}
reg.forward <- lm(G3 ~ G2 + G1 + failures + reason + absences + sex + school + traveltime + health, data = student_por, subset = Z)

g3_pred_forward <- predict(reg.forward, student_por)
```

```{r}
plot(student_por$G3[-Z], g3_pred_forward[-Z], xlab = "Actual Grade", ylab = "Predicted Grade", main = "Actual vs. Predicted: Forward Step Model")
abline(0, 1)
```

```{r}
mse_valSet <- mean((student_por$G3 - g3_pred_forward)[-Z] ^ 2)
mse_valSet
```

The MSE for the Forward STep Model is 1.459.

## Ridge Regression & LASSO Preparation

```{r}
G3_test <- student_por$G3[-Z]

# Creating model matrix for rr and lasso calculations
x_col <- model.matrix(G3 ~ ., student_por)[, -1]
```

## Ridge Regression

Now we are going to look at Ridge Regression.

```{r}
set.seed(1)
cv.out1 <- cv.glmnet(x_col, student_por$G3, alpha = 0) # alpha = 0 ---> Ridge regression
predict(cv.out1, s = cv.out1$lambda.min, type = "coefficients")
```

```{r}
rr.mod <- glmnet(x_col[Z, ], student_por$G3[Z], alpha = 0, lambda = cv.out1$lambda.min)
rr.pred <- predict(rr.mod, s = cv.out1$lambda.min, newx = x_col[-Z, ])

mse_rr <- mean((rr.pred - student_por$G3[-Z])^2)
mse_rr
```

The MSE for Ridge Regression is 1.597.

$\lambda = .30$

## LASSO

Next we are going to look at LASSO. 

```{r}
set.seed(1)
cv.out2 <- cv.glmnet(x_col, student_por$G3, alpha = 1)
predict(cv.out2, s = cv.out2$lambda.min, type = "coefficients")
```

$\lambda = .10$

```{r}
lasso.mod <- glmnet(x_col[Z, ], student_por$G3[Z], alpha = 1, lambda = cv.out2$lambda.min)
lasso.pred <- predict(lasso.mod, s = cv.out2$lambda.min, newx = x_col[-Z, ])

mse_lasso <- mean((lasso.pred - student_por$G3[-Z])^2)
mse_lasso
```

The MSE for Lasso is 1.528.

```{r, include = FALSE}
## student_por.dimred <- lm(G3 ~ school + sex + reason + failures + G1 + G2, student_por)
## summary(student_por.dimred)
```

## Principal Component Regression

Now we are going to look at principal component regression.

```{r}
pcr.fit <- pcr(G3 ~ ., data = student_por, scale = TRUE, validation = "CV")
summary(pcr.fit)
```

```{r}
R2.pcr = as.numeric(R2(pcr.fit, estimate="train")$val)
mse.pcr = as.numeric(MSEP(pcr.fit, estimate="train")$val)

R2.pcr
mse.pcr
```

PCR attains the lowest prediction MSE = 1.458 when all 41 principal components are included. This result, which would be overly cumbersome to analyze within this project's scope, does not lend itself well to further analysis compared to more dimension-reduced models. If we were to compromise the number of principal components, we would still need to include 20+ to create a model with an MSE that is comparable to our previous models. Therefore, we will not be suggesting a candidate model based on principal component regression.

## Partial Least Squares Regression

```{r}
pls.fit <- plsr(G3 ~ ., data = student_por, scale = TRUE, validation = "CV")
summary(pls.fit)
```

```{r}
R2.pls = as.numeric(R2(pls.fit, estimate="train")$val)
mse.pls = as.numeric(MSEP(pls.fit, estimate="train")$val)

R2.pls
mse.pls

mse.pls <- mse.pls[10]
```

PLS attains the lowest predict MSE = 1.458853 with 18 principal components. If we were going to consider one of these models as a candidate model, I would consider sacrificing a little prediction accuracy for simplicity/dimension reduction. I would recommend using the model with 10 principal components because the MSE is 1.459062 which is only slightly higher than that with 18 with 8 fewer principal components. 

## Comparing MSEs

Now that we have proposed all of our candidate models, we are going to take a look at the MSE to determine our final model.

```{r}
tibble("method" = c("BIC-Minimized", "Cp-Minimized", "LASSO", "Linear Regression", "Ridge Regression", "AIC-Minimized", "PLS"),
       "MSE" = c(mse_bic, mse_cp, mse_lasso, mse_lm, mse_rr, mse_valSet, mse.pls)) %>%
  arrange(MSE)
```

Based on the MSE, we are going to examine the top three models and determine which one has the best balance of number of predictors and accuracy.

```{r}
reg.bestsubBIC
reg.forward # Picking this one
```

Picking forward-selected candidate model because best balance of number of predictors while sacrificing only a little accuracy.

# Conclusion

After examining a variety of candidate models, we have decided to use the model generated by forward step selection. We believe that this model does not eliminate too many variables while maintaining a relatively low MSE of 1.459. We have run the model again with the full data set below.

```{r}
reg.forward_full <- lm(G3 ~ G1 + G2 + failures + reason + absences + sex + school + traveltime + health, student_por)

summary(reg.forward_full)
```

Our final model is as follows:

$$ \widehat{G3} = 0.441 + 0.137 (G1) + 0.880 (G2) -0.240(failures) - 0.092(reasonhome) - 0.450(reasonother) - 0.165(reasonrep) + 0.016(absences) - 0.200(sexMale) - 0.230(schoolMS) + 0.112(traveltime) - 0.054(health)$$

Let's look at each of these variables and what they mean.

- G1 is the student's grade during the first term
- G2 is the student's grade during the second term
- Failures is the number of past class failures a student had
- Reason is the reason a student attended a certain school
- Absences is the number of absences a student had
- Sex is the sex of the student
- School is a the name of the school the student attended
- Traveltime is the amount of time it took a student to get to school
- Health is the current health status of the student

Based on our final model, these are the variables that are significant when attempting to predict a student's final grade in Portuguese class (G3). 

```{r, include = FALSE}
pairs(tibble(student_por$G1,
             student_por$G2,
             student_por$failures,
             student_por$reason,
             student_por$absences,
             student_por$school,
             student_por$traveltime,
             student_por$health))

cor(data.frame(student_por$G1, student_por$G2))

car::vif(reg.forward)


summary(reg.forward_mod)

car::vif(reg.forward_mod)
```

